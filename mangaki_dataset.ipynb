{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_id</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hayate the Combat Butler! Cuties</td>\n",
       "      <td>anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Caffe Latte Rhapsody</td>\n",
       "      <td>manga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Dragon Ball</td>\n",
       "      <td>anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Accel World</td>\n",
       "      <td>manga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Soukyuu no Fafner: Right of Left</td>\n",
       "      <td>anime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_id                             title category\n",
       "0        0  Hayate the Combat Butler! Cuties    anime\n",
       "1        1              Caffe Latte Rhapsody    manga\n",
       "2        2                       Dragon Ball    anime\n",
       "3        3                       Accel World    manga\n",
       "4        4  Soukyuu no Fafner: Right of Left    anime"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime = pd.read_csv('./mangaki-data-challenge-0908/titles.csv')\n",
    "anime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>album</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime</th>\n",
       "      <td>7088</td>\n",
       "      <td>7088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manga</th>\n",
       "      <td>2808</td>\n",
       "      <td>2808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          work_id  title\n",
       "category                \n",
       "album           1      1\n",
       "anime        7088   7088\n",
       "manga        2808   2808"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime.groupby('category').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anime = anime['category'].isin(['anime', 'manga'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_id</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>9892</td>\n",
       "      <td>Starship Operators</td>\n",
       "      <td>anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9893</th>\n",
       "      <td>9893</td>\n",
       "      <td>Project: City Flying in the Sky</td>\n",
       "      <td>anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9894</th>\n",
       "      <td>9894</td>\n",
       "      <td>Coeur de sirene</td>\n",
       "      <td>manga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9895</th>\n",
       "      <td>9895</td>\n",
       "      <td>Hayate no Gotoku! OVA</td>\n",
       "      <td>anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9896</th>\n",
       "      <td>9896</td>\n",
       "      <td>Say \"I Love You\". Specials</td>\n",
       "      <td>anime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      work_id                            title category\n",
       "9892     9892               Starship Operators    anime\n",
       "9893     9893  Project: City Flying in the Sky    anime\n",
       "9894     9894                  Coeur de sirene    manga\n",
       "9895     9895            Hayate no Gotoku! OVA    anime\n",
       "9896     9896       Say \"I Love You\". Specials    anime"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>717</td>\n",
       "      <td>8025</td>\n",
       "      <td>dislike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1106</td>\n",
       "      <td>1027</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970</td>\n",
       "      <td>3949</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1685</td>\n",
       "      <td>9815</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1703</td>\n",
       "      <td>3482</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  work_id   rating\n",
       "0      717     8025  dislike\n",
       "1     1106     1027  neutral\n",
       "2     1970     3949  neutral\n",
       "3     1685     9815     like\n",
       "4     1703     3482     like"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('./mangaki-data-challenge-0908/watched.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.replace({'dislike': '1'}, regex=True)\n",
    "ratings = ratings.replace({'neutral': '2'}, regex=True)\n",
    "ratings = ratings.replace({'like': '3'}, regex=True)\n",
    "ratings = ratings.replace({'love': '4'}, regex=True)\n",
    "\n",
    "ratings['rating'] = ratings['rating'].astype(float)\n",
    "ratings['rating'] = ratings['rating'] / 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>717</td>\n",
       "      <td>8025</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1106</td>\n",
       "      <td>1027</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970</td>\n",
       "      <td>3949</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1685</td>\n",
       "      <td>9815</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1703</td>\n",
       "      <td>3482</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  work_id  rating\n",
       "0      717     8025    0.25\n",
       "1     1106     1027    0.50\n",
       "2     1970     3949    0.50\n",
       "3     1685     9815    0.75\n",
       "4     1703     3482    0.75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9891</th>\n",
       "      <td>877</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>152</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9893</th>\n",
       "      <td>1522</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9894</th>\n",
       "      <td>985</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9896</th>\n",
       "      <td>1789</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  rating\n",
       "work_id                 \n",
       "9891         877    0.75\n",
       "9892         152    0.75\n",
       "9893        1522    0.75\n",
       "9894         985    0.25\n",
       "9896        1789    0.50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.sort_values('work_id').groupby('work_id').first().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users 1963\n"
     ]
    }
   ],
   "source": [
    "print('Number of users', len(ratings.groupby('user_id').first()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "work_id\n",
       "0       0.500000\n",
       "1       0.750000\n",
       "2       0.684426\n",
       "3       0.700000\n",
       "4       0.642857\n",
       "5       0.683036\n",
       "6       0.500000\n",
       "7       0.666667\n",
       "9       0.593750\n",
       "10      0.750000\n",
       "11      0.750000\n",
       "12      0.750000\n",
       "16      0.583333\n",
       "17      0.642857\n",
       "18      0.607143\n",
       "20      0.250000\n",
       "21      0.687500\n",
       "22      0.500000\n",
       "23      0.590909\n",
       "24      0.652174\n",
       "25      0.375000\n",
       "26      0.671875\n",
       "27      0.662534\n",
       "28      0.690217\n",
       "29      0.666667\n",
       "30      0.750000\n",
       "32      0.750000\n",
       "33      0.500000\n",
       "34      0.500000\n",
       "35      0.500000\n",
       "          ...   \n",
       "9864    0.833333\n",
       "9865    0.700000\n",
       "9866    0.750000\n",
       "9867    0.750000\n",
       "9868    0.639744\n",
       "9869    0.601190\n",
       "9870    0.750000\n",
       "9871    0.500000\n",
       "9872    0.500000\n",
       "9873    0.500000\n",
       "9874    0.250000\n",
       "9875    0.666667\n",
       "9876    0.666667\n",
       "9877    0.615385\n",
       "9878    0.500000\n",
       "9879    0.812500\n",
       "9880    0.750000\n",
       "9881    0.833333\n",
       "9882    0.750000\n",
       "9884    0.562500\n",
       "9885    0.725000\n",
       "9886    0.617647\n",
       "9887    0.650000\n",
       "9889    0.750000\n",
       "9890    1.000000\n",
       "9891    0.750000\n",
       "9892    0.687500\n",
       "9893    0.750000\n",
       "9894    0.250000\n",
       "9896    0.625000\n",
       "Name: rating, Length: 8584, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average rating for works\n",
    "ratings.groupby('work_id').mean()['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding 0 ratings for non rated works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_ratings = []\n",
    "\n",
    "for work_id in range(len(anime)):\n",
    "    # if not rated by any user\n",
    "    if ratings[ratings['work_id'] == work_id].empty:\n",
    "        dummy_ratings.append({'work_id': int(work_id), 'rating': 0, 'user_id': 0})\n",
    "\n",
    "ratings = ratings.append(pd.DataFrame(dummy_ratings), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9897\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9893</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9894</th>\n",
       "      <td>0.25</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9895</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9896</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating  user_id\n",
       "work_id                 \n",
       "9892       0.75     1054\n",
       "9893       0.75     1522\n",
       "9894       0.25      985\n",
       "9895       0.00        0\n",
       "9896       0.50     1789"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(anime))\n",
    "ratings.sort_values('work_id').groupby('work_id').first().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>work_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9887</th>\n",
       "      <th>9888</th>\n",
       "      <th>9889</th>\n",
       "      <th>9890</th>\n",
       "      <th>9891</th>\n",
       "      <th>9892</th>\n",
       "      <th>9893</th>\n",
       "      <th>9894</th>\n",
       "      <th>9895</th>\n",
       "      <th>9896</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 9897 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "work_id  0     1     2     3     4     5     6     7     8     9     ...   \\\n",
       "user_id                                                              ...    \n",
       "0         0.0   0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "1         0.0   0.0  0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "2         0.0   0.0  0.75   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "3         0.0   0.0  0.50   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "4         0.0   0.0  0.75   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "\n",
       "work_id  9887  9888  9889  9890  9891  9892  9893  9894  9895  9896  \n",
       "user_id                                                              \n",
       "0         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 9897 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piv = ratings.pivot_table(index=['user_id'], columns=['work_id'], values='rating')\n",
    "piv.fillna(0, inplace=True)\n",
    "piv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Deep AutoEncoders for Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "\n",
    "from tensorflow.python.estimator.model_fn import EstimatorSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0-rc1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = None\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.005\n",
    "DROPOUT = 0.8\n",
    "BATCH_SIZE = 64\n",
    "OPTIMIZER = tf.train.AdagradOptimizer #tf.train.GradientDescentOptimizer\n",
    "\n",
    "LOGDIR = './model_files/deep_ae/adagrad_64_0.005_0.8_64_128_128_128_64_dense_re_last_activation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    # 1. Configure the model via TensorFlow operations\n",
    "    # Input Layer\n",
    "    x = features['x']\n",
    "\n",
    "    encoder1 = tf.layers.dense(inputs=x, units=64, activation=tf.nn.selu, name='encoder1')\n",
    "    encoder2 = tf.layers.dense(inputs=encoder1, units=128, activation=tf.nn.selu, name='encoder2')\n",
    "\n",
    "    bottleneck = tf.layers.dense(inputs=encoder2, units=128, name='bottleneck')\n",
    "    dropout = tf.layers.dropout(inputs=bottleneck, rate=params['dropout'], training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    decoder1 = tf.layers.dense(inputs=dropout, units=128, activation=tf.nn.selu, name='decoder1')\n",
    "    decoder2 = tf.layers.dense(inputs=decoder1, units=64, activation=tf.nn.selu, name='decoder2')\n",
    "\n",
    "    y = tf.layers.dense(inputs=decoder2, units=x.get_shape()[1], activation=tf.nn.selu, name=\"out\")\n",
    "\n",
    "     # Dense re-feeding in the same pass (not two optimization step per iteration)\n",
    "    encoder1_re = tf.layers.dense(inputs=y, units=64, activation=tf.nn.selu, reuse=True, name='encoder1')\n",
    "    encoder2_re = tf.layers.dense(inputs=encoder1_re, units=128, activation=tf.nn.selu, reuse=True, name='encoder2')\n",
    "\n",
    "    bottleneck_re = tf.layers.dense(inputs=encoder2_re, units=128, reuse=True, name='bottleneck')\n",
    "    dropout_re = tf.layers.dropout(inputs=bottleneck_re, rate=params['dropout'], training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    decoder1_re = tf.layers.dense(inputs=dropout_re, units=128, activation=tf.nn.selu, reuse=True, name='decoder1')\n",
    "    decoder2_re = tf.layers.dense(inputs=decoder1_re, units=64, activation=tf.nn.selu, reuse=True, name='decoder2')\n",
    "\n",
    "    y_re = tf.layers.dense(inputs=decoder2_re, units=x.get_shape()[1], reuse=True, activation=tf.nn.selu, name=\"out\")\n",
    "# FIXME sigmoid activation??\n",
    "\n",
    "    # Loss function for training/evaluation\n",
    "    # Masked Mean Square Error \n",
    "    # mask = tf.where(x != 0, 1, 0, name='loss_mask')\n",
    "    # loss = tf.divide(tf.multiply(mask, tf.squared_difference(x, y)), tf.sum(mask)) +\n",
    "    #        tf.losses.mean_squared_error(y, y_re)\n",
    "\n",
    "\n",
    "    weight = tf.cast(tf.greater(x, 0), tf.float32)\n",
    "    # loss for first backprop + loss for dense re-feeding\n",
    "    loss = tf.losses.mean_squared_error(x, y, weight) + tf.losses.mean_squared_error(y, y_re)\n",
    "    \n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    tf.summary.scalar(\"rmse\", tf.sqrt(loss))\n",
    "\n",
    "    eval_metric_ops = {\n",
    "        \"rmse\": tf.metrics.root_mean_squared_error(x, y, weight)\n",
    "    }\n",
    "    # 3. Define the training operation/optimizer\n",
    "    optimizer = params['optimizer'](learning_rate=params[\"learning_rate\"])\n",
    "    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "    # 4. Generate predictions\n",
    "    # 5. Return predictions/loss/train_op/eval_metric_ops in EstimatorSpec object\n",
    "    return EstimatorSpec(mode, y, loss, train_op, eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_tf_random_seed': 1, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './model_files/deep_ae/adagrad_64_0.005_0.8_64_128_128_128_64_dense_re_last_activation', '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      ", '_log_step_count_steps': 100, '_keep_checkpoint_max': 5}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./model_files/deep_ae/adagrad_64_0.005_0.8_64_128_128_128_64_dense_re_last_activation/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.496263, step = 1\n",
      "INFO:tensorflow:global_step/sec: 90.7456\n",
      "INFO:tensorflow:loss = 0.4647, step = 101 (1.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.375\n",
      "INFO:tensorflow:loss = 0.450493, step = 201 (0.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.662\n",
      "INFO:tensorflow:loss = 0.372682, step = 301 (0.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.678\n",
      "INFO:tensorflow:loss = 0.223262, step = 401 (0.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.695\n",
      "INFO:tensorflow:loss = 0.202055, step = 501 (0.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.672\n",
      "INFO:tensorflow:loss = 0.151942, step = 601 (0.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.218\n",
      "INFO:tensorflow:loss = 0.137425, step = 701 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.285\n",
      "INFO:tensorflow:loss = 0.146456, step = 801 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.672\n",
      "INFO:tensorflow:loss = 0.137861, step = 901 (0.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.742\n",
      "INFO:tensorflow:loss = 0.124185, step = 1001 (0.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.747\n",
      "INFO:tensorflow:loss = 0.127478, step = 1101 (0.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.081\n",
      "INFO:tensorflow:loss = 0.107498, step = 1201 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.116\n",
      "INFO:tensorflow:loss = 0.0968258, step = 1301 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.607\n",
      "INFO:tensorflow:loss = 0.0980813, step = 1401 (0.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.309\n",
      "INFO:tensorflow:loss = 0.0980695, step = 1501 (0.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.672\n",
      "INFO:tensorflow:loss = 0.0848722, step = 1601 (0.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.3\n",
      "INFO:tensorflow:loss = 0.0803776, step = 1701 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.527\n",
      "INFO:tensorflow:loss = 0.0988835, step = 1801 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.118\n",
      "INFO:tensorflow:loss = 0.0712122, step = 1901 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.871\n",
      "INFO:tensorflow:loss = 0.0729898, step = 2001 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.466\n",
      "INFO:tensorflow:loss = 0.0748401, step = 2101 (0.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.514\n",
      "INFO:tensorflow:loss = 0.0759226, step = 2201 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.701\n",
      "INFO:tensorflow:loss = 0.0759909, step = 2301 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.94\n",
      "INFO:tensorflow:loss = 0.0676847, step = 2401 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.421\n",
      "INFO:tensorflow:loss = 0.0732116, step = 2501 (0.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.268\n",
      "INFO:tensorflow:loss = 0.065091, step = 2601 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.967\n",
      "INFO:tensorflow:loss = 0.0616478, step = 2701 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.819\n",
      "INFO:tensorflow:loss = 0.0670266, step = 2801 (0.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.057\n",
      "INFO:tensorflow:loss = 0.0650115, step = 2901 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.453\n",
      "INFO:tensorflow:loss = 0.0674575, step = 3001 (0.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.001\n",
      "INFO:tensorflow:loss = 0.0618802, step = 3101 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.504\n",
      "INFO:tensorflow:loss = 0.0677586, step = 3201 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.147\n",
      "INFO:tensorflow:loss = 0.0696551, step = 3301 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.464\n",
      "INFO:tensorflow:loss = 0.0740236, step = 3401 (0.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.708\n",
      "INFO:tensorflow:loss = 0.0616116, step = 3501 (0.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.598\n",
      "INFO:tensorflow:loss = 0.0574078, step = 3601 (0.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.235\n",
      "INFO:tensorflow:loss = 0.0565561, step = 3701 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.975\n",
      "INFO:tensorflow:loss = 0.0572108, step = 3801 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.473\n",
      "INFO:tensorflow:loss = 0.0446726, step = 3901 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.576\n",
      "INFO:tensorflow:loss = 0.0505534, step = 4001 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.757\n",
      "INFO:tensorflow:loss = 0.0503289, step = 4101 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.535\n",
      "INFO:tensorflow:loss = 0.0520425, step = 4201 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.435\n",
      "INFO:tensorflow:loss = 0.0567174, step = 4301 (0.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.976\n",
      "INFO:tensorflow:loss = 0.0563854, step = 4401 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.521\n",
      "INFO:tensorflow:loss = 0.0493239, step = 4501 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.57\n",
      "INFO:tensorflow:loss = 0.0567633, step = 4601 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.55\n",
      "INFO:tensorflow:loss = 0.0565589, step = 4701 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.269\n",
      "INFO:tensorflow:loss = 0.0549297, step = 4801 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.002\n",
      "INFO:tensorflow:loss = 0.0554134, step = 4901 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.331\n",
      "INFO:tensorflow:loss = 0.0569027, step = 5001 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.026\n",
      "INFO:tensorflow:loss = 0.0577727, step = 5101 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.007\n",
      "INFO:tensorflow:loss = 0.0446139, step = 5201 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.397\n",
      "INFO:tensorflow:loss = 0.0511266, step = 5301 (0.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.839\n",
      "INFO:tensorflow:loss = 0.0542557, step = 5401 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.373\n",
      "INFO:tensorflow:loss = 0.0420023, step = 5501 (0.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.2\n",
      "INFO:tensorflow:loss = 0.0471836, step = 5601 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.697\n",
      "INFO:tensorflow:loss = 0.0497636, step = 5701 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.48\n",
      "INFO:tensorflow:loss = 0.0448451, step = 5801 (0.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.606\n",
      "INFO:tensorflow:loss = 0.050846, step = 5901 (0.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.303\n",
      "INFO:tensorflow:loss = 0.0443576, step = 6001 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.971\n",
      "INFO:tensorflow:loss = 0.037675, step = 6101 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.879\n",
      "INFO:tensorflow:loss = 0.0436738, step = 6201 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.141\n",
      "INFO:tensorflow:loss = 0.0486099, step = 6301 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.055\n",
      "INFO:tensorflow:loss = 0.0470285, step = 6401 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.824\n",
      "INFO:tensorflow:loss = 0.0447541, step = 6501 (0.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.621\n",
      "INFO:tensorflow:loss = 0.0378519, step = 6601 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.71\n",
      "INFO:tensorflow:loss = 0.0458678, step = 6701 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.996\n",
      "INFO:tensorflow:loss = 0.0505841, step = 6801 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.942\n",
      "INFO:tensorflow:loss = 0.0459008, step = 6901 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.859\n",
      "INFO:tensorflow:loss = 0.040706, step = 7001 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.304\n",
      "INFO:tensorflow:loss = 0.0459065, step = 7101 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.538\n",
      "INFO:tensorflow:loss = 0.0400549, step = 7201 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.244\n",
      "INFO:tensorflow:loss = 0.0474812, step = 7301 (0.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.871\n",
      "INFO:tensorflow:loss = 0.0466829, step = 7401 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.517\n",
      "INFO:tensorflow:loss = 0.039128, step = 7501 (0.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.646\n",
      "INFO:tensorflow:loss = 0.0463918, step = 7601 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.757\n",
      "INFO:tensorflow:loss = 0.0461047, step = 7701 (0.973 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 102.429\n",
      "INFO:tensorflow:loss = 0.0497101, step = 7801 (0.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.396\n",
      "INFO:tensorflow:loss = 0.0438645, step = 7901 (0.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.65\n",
      "INFO:tensorflow:loss = 0.045565, step = 8001 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.628\n",
      "INFO:tensorflow:loss = 0.0394275, step = 8101 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.552\n",
      "INFO:tensorflow:loss = 0.0442589, step = 8201 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.345\n",
      "INFO:tensorflow:loss = 0.0470038, step = 8301 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.178\n",
      "INFO:tensorflow:loss = 0.0475958, step = 8401 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.869\n",
      "INFO:tensorflow:loss = 0.0413456, step = 8501 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.69\n",
      "INFO:tensorflow:loss = 0.0395053, step = 8601 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.214\n",
      "INFO:tensorflow:loss = 0.0444458, step = 8701 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.109\n",
      "INFO:tensorflow:loss = 0.0379105, step = 8801 (0.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.43\n",
      "INFO:tensorflow:loss = 0.0426298, step = 8901 (0.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.349\n",
      "INFO:tensorflow:loss = 0.0463483, step = 9001 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.83\n",
      "INFO:tensorflow:loss = 0.0463668, step = 9101 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.837\n",
      "INFO:tensorflow:loss = 0.037589, step = 9201 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.446\n",
      "INFO:tensorflow:loss = 0.0416082, step = 9301 (0.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.679\n",
      "INFO:tensorflow:loss = 0.0447526, step = 9401 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.24\n",
      "INFO:tensorflow:loss = 0.0414553, step = 9501 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.111\n",
      "INFO:tensorflow:loss = 0.0429854, step = 9601 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.267\n",
      "INFO:tensorflow:loss = 0.04095, step = 9701 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.961\n",
      "INFO:tensorflow:loss = 0.0400239, step = 9801 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.586\n",
      "INFO:tensorflow:loss = 0.0409901, step = 9901 (0.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.555\n",
      "INFO:tensorflow:loss = 0.0444539, step = 10001 (0.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.757\n",
      "INFO:tensorflow:loss = 0.0382811, step = 10101 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.3\n",
      "INFO:tensorflow:loss = 0.042564, step = 10201 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.007\n",
      "INFO:tensorflow:loss = 0.0439646, step = 10301 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.46\n",
      "INFO:tensorflow:loss = 0.0442177, step = 10401 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.54\n",
      "INFO:tensorflow:loss = 0.041332, step = 10501 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.195\n",
      "INFO:tensorflow:loss = 0.0421693, step = 10601 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.351\n",
      "INFO:tensorflow:loss = 0.0362119, step = 10701 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.05\n",
      "INFO:tensorflow:loss = 0.0447017, step = 10801 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.394\n",
      "INFO:tensorflow:loss = 0.0407518, step = 10901 (0.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.803\n",
      "INFO:tensorflow:loss = 0.0412639, step = 11001 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.158\n",
      "INFO:tensorflow:loss = 0.0373622, step = 11101 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.336\n",
      "INFO:tensorflow:loss = 0.0370924, step = 11201 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.236\n",
      "INFO:tensorflow:loss = 0.0338271, step = 11301 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.343\n",
      "INFO:tensorflow:loss = 0.0407839, step = 11401 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.816\n",
      "INFO:tensorflow:loss = 0.0358422, step = 11501 (0.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.384\n",
      "INFO:tensorflow:loss = 0.0440063, step = 11601 (0.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.333\n",
      "INFO:tensorflow:loss = 0.0421138, step = 11701 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.429\n",
      "INFO:tensorflow:loss = 0.0340628, step = 11801 (0.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.137\n",
      "INFO:tensorflow:loss = 0.0345091, step = 11901 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.141\n",
      "INFO:tensorflow:loss = 0.0386344, step = 12001 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.233\n",
      "INFO:tensorflow:loss = 0.0387148, step = 12101 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.198\n",
      "INFO:tensorflow:loss = 0.040755, step = 12201 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.064\n",
      "INFO:tensorflow:loss = 0.0384121, step = 12301 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.95\n",
      "INFO:tensorflow:loss = 0.035143, step = 12401 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.508\n",
      "INFO:tensorflow:loss = 0.0363163, step = 12501 (0.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.161\n",
      "INFO:tensorflow:loss = 0.0354913, step = 12601 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.295\n",
      "INFO:tensorflow:loss = 0.0377325, step = 12701 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.176\n",
      "INFO:tensorflow:loss = 0.0379353, step = 12801 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.805\n",
      "INFO:tensorflow:loss = 0.0380247, step = 12901 (0.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.998\n",
      "INFO:tensorflow:loss = 0.0404753, step = 13001 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.876\n",
      "INFO:tensorflow:loss = 0.037384, step = 13101 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.33\n",
      "INFO:tensorflow:loss = 0.0331241, step = 13201 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.972\n",
      "INFO:tensorflow:loss = 0.0424527, step = 13301 (0.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.8\n",
      "INFO:tensorflow:loss = 0.0341123, step = 13401 (0.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.963\n",
      "INFO:tensorflow:loss = 0.0387995, step = 13501 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.775\n",
      "INFO:tensorflow:loss = 0.0329834, step = 13601 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.852\n",
      "INFO:tensorflow:loss = 0.0339688, step = 13701 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.597\n",
      "INFO:tensorflow:loss = 0.035375, step = 13801 (0.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.032\n",
      "INFO:tensorflow:loss = 0.0434766, step = 13901 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.091\n",
      "INFO:tensorflow:loss = 0.0355989, step = 14001 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.244\n",
      "INFO:tensorflow:loss = 0.034583, step = 14101 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.774\n",
      "INFO:tensorflow:loss = 0.0387487, step = 14201 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.799\n",
      "INFO:tensorflow:loss = 0.0354323, step = 14301 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.211\n",
      "INFO:tensorflow:loss = 0.0405167, step = 14401 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.195\n",
      "INFO:tensorflow:loss = 0.0379144, step = 14501 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.107\n",
      "INFO:tensorflow:loss = 0.0343089, step = 14601 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.749\n",
      "INFO:tensorflow:loss = 0.0300616, step = 14701 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.492\n",
      "INFO:tensorflow:loss = 0.0335043, step = 14801 (0.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.308\n",
      "INFO:tensorflow:loss = 0.0377555, step = 14901 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.229\n",
      "INFO:tensorflow:loss = 0.0327289, step = 15001 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.68\n",
      "INFO:tensorflow:loss = 0.0370703, step = 15101 (0.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.793\n",
      "INFO:tensorflow:loss = 0.0313692, step = 15201 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.764\n",
      "INFO:tensorflow:loss = 0.0368473, step = 15301 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.664\n",
      "INFO:tensorflow:loss = 0.0368035, step = 15401 (0.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.205\n",
      "INFO:tensorflow:loss = 0.0299706, step = 15501 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.988\n",
      "INFO:tensorflow:loss = 0.0355361, step = 15601 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.113\n",
      "INFO:tensorflow:loss = 0.0404471, step = 15701 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.225\n",
      "INFO:tensorflow:loss = 0.038373, step = 15801 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.88\n",
      "INFO:tensorflow:loss = 0.0354053, step = 15901 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.803\n",
      "INFO:tensorflow:loss = 0.0283392, step = 16001 (0.973 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 103.004\n",
      "INFO:tensorflow:loss = 0.0371818, step = 16101 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.659\n",
      "INFO:tensorflow:loss = 0.0362574, step = 16201 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.86\n",
      "INFO:tensorflow:loss = 0.0296875, step = 16301 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.008\n",
      "INFO:tensorflow:loss = 0.0342949, step = 16401 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.475\n",
      "INFO:tensorflow:loss = 0.0410287, step = 16501 (0.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.234\n",
      "INFO:tensorflow:loss = 0.0324789, step = 16601 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.576\n",
      "INFO:tensorflow:loss = 0.0347208, step = 16701 (0.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.876\n",
      "INFO:tensorflow:loss = 0.0365158, step = 16801 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.014\n",
      "INFO:tensorflow:loss = 0.0377228, step = 16901 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.741\n",
      "INFO:tensorflow:loss = 0.0394961, step = 17001 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.012\n",
      "INFO:tensorflow:loss = 0.0380116, step = 17101 (0.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.788\n",
      "INFO:tensorflow:loss = 0.032675, step = 17201 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.048\n",
      "INFO:tensorflow:loss = 0.0398928, step = 17301 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.557\n",
      "INFO:tensorflow:loss = 0.0352611, step = 17401 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.107\n",
      "INFO:tensorflow:loss = 0.0309456, step = 17501 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.535\n",
      "INFO:tensorflow:loss = 0.0312176, step = 17601 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.062\n",
      "INFO:tensorflow:loss = 0.0429139, step = 17701 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.394\n",
      "INFO:tensorflow:loss = 0.0360131, step = 17801 (0.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.293\n",
      "INFO:tensorflow:loss = 0.0351416, step = 17901 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.655\n",
      "INFO:tensorflow:loss = 0.0327732, step = 18001 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.251\n",
      "INFO:tensorflow:loss = 0.0409375, step = 18101 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.343\n",
      "INFO:tensorflow:loss = 0.0422612, step = 18201 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.693\n",
      "INFO:tensorflow:loss = 0.0359925, step = 18301 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.706\n",
      "INFO:tensorflow:loss = 0.0387228, step = 18401 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.322\n",
      "INFO:tensorflow:loss = 0.0336228, step = 18501 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.406\n",
      "INFO:tensorflow:loss = 0.0348683, step = 18601 (0.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.408\n",
      "INFO:tensorflow:loss = 0.0308368, step = 18701 (0.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.313\n",
      "INFO:tensorflow:loss = 0.0324909, step = 18801 (0.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.623\n",
      "INFO:tensorflow:loss = 0.0371396, step = 18901 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.927\n",
      "INFO:tensorflow:loss = 0.0318055, step = 19001 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.614\n",
      "INFO:tensorflow:loss = 0.0392877, step = 19101 (0.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.904\n",
      "INFO:tensorflow:loss = 0.0362252, step = 19201 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.684\n",
      "INFO:tensorflow:loss = 0.0324008, step = 19301 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.916\n",
      "INFO:tensorflow:loss = 0.0335779, step = 19401 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.097\n",
      "INFO:tensorflow:loss = 0.0350088, step = 19501 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.555\n",
      "INFO:tensorflow:loss = 0.0371445, step = 19601 (0.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.933\n",
      "INFO:tensorflow:loss = 0.0300648, step = 19701 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.595\n",
      "INFO:tensorflow:loss = 0.0348702, step = 19801 (0.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.041\n",
      "INFO:tensorflow:loss = 0.0366115, step = 19901 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.682\n",
      "INFO:tensorflow:loss = 0.0364868, step = 20001 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.639\n",
      "INFO:tensorflow:loss = 0.0303198, step = 20101 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.111\n",
      "INFO:tensorflow:loss = 0.0332913, step = 20201 (0.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.291\n",
      "INFO:tensorflow:loss = 0.0339311, step = 20301 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.092\n",
      "INFO:tensorflow:loss = 0.0366313, step = 20401 (0.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.604\n",
      "INFO:tensorflow:loss = 0.0325057, step = 20501 (0.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.239\n",
      "INFO:tensorflow:loss = 0.0377585, step = 20601 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.986\n",
      "INFO:tensorflow:loss = 0.0384724, step = 20701 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.932\n",
      "INFO:tensorflow:loss = 0.0396918, step = 20801 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.892\n",
      "INFO:tensorflow:loss = 0.0321178, step = 20901 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.855\n",
      "INFO:tensorflow:loss = 0.034416, step = 21001 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.717\n",
      "INFO:tensorflow:loss = 0.0348364, step = 21101 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.798\n",
      "INFO:tensorflow:loss = 0.0297199, step = 21201 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.59\n",
      "INFO:tensorflow:loss = 0.03413, step = 21301 (0.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.962\n",
      "INFO:tensorflow:loss = 0.0326761, step = 21401 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.242\n",
      "INFO:tensorflow:loss = 0.0402194, step = 21501 (0.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.18\n",
      "INFO:tensorflow:loss = 0.0310023, step = 21601 (0.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.72\n",
      "INFO:tensorflow:loss = 0.0356907, step = 21701 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.812\n",
      "INFO:tensorflow:loss = 0.0400576, step = 21801 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.961\n",
      "INFO:tensorflow:loss = 0.0330838, step = 21901 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.381\n",
      "INFO:tensorflow:loss = 0.0385229, step = 22001 (0.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.687\n",
      "INFO:tensorflow:loss = 0.0363063, step = 22101 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.887\n",
      "INFO:tensorflow:loss = 0.0334996, step = 22201 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.71\n",
      "INFO:tensorflow:loss = 0.0444959, step = 22301 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.09\n",
      "INFO:tensorflow:loss = 0.0355594, step = 22401 (0.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.186\n",
      "INFO:tensorflow:loss = 0.0273475, step = 22501 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.766\n",
      "INFO:tensorflow:loss = 0.0320759, step = 22601 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.331\n",
      "INFO:tensorflow:loss = 0.0366777, step = 22701 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.674\n",
      "INFO:tensorflow:loss = 0.0336069, step = 22801 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.553\n",
      "INFO:tensorflow:loss = 0.0313284, step = 22901 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.269\n",
      "INFO:tensorflow:loss = 0.0341666, step = 23001 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.179\n",
      "INFO:tensorflow:loss = 0.0290367, step = 23101 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.115\n",
      "INFO:tensorflow:loss = 0.0350015, step = 23201 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.575\n",
      "INFO:tensorflow:loss = 0.0313534, step = 23301 (0.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.417\n",
      "INFO:tensorflow:loss = 0.0303054, step = 23401 (0.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.666\n",
      "INFO:tensorflow:loss = 0.0330805, step = 23501 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.112\n",
      "INFO:tensorflow:loss = 0.0386527, step = 23601 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.588\n",
      "INFO:tensorflow:loss = 0.0376233, step = 23701 (0.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.843\n",
      "INFO:tensorflow:loss = 0.0335878, step = 23801 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.917\n",
      "INFO:tensorflow:loss = 0.0371934, step = 23901 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.574\n",
      "INFO:tensorflow:loss = 0.0303129, step = 24001 (0.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.01\n",
      "INFO:tensorflow:loss = 0.0339172, step = 24101 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.006\n",
      "INFO:tensorflow:loss = 0.0336052, step = 24201 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0302188, step = 24301 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.784\n",
      "INFO:tensorflow:loss = 0.0332318, step = 24401 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.576\n",
      "INFO:tensorflow:loss = 0.03252, step = 24501 (0.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.371\n",
      "INFO:tensorflow:loss = 0.0303276, step = 24601 (0.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.372\n",
      "INFO:tensorflow:loss = 0.0369382, step = 24701 (0.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.94\n",
      "INFO:tensorflow:loss = 0.0333401, step = 24801 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.219\n",
      "INFO:tensorflow:loss = 0.0319695, step = 24901 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.045\n",
      "INFO:tensorflow:loss = 0.036047, step = 25001 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.958\n",
      "INFO:tensorflow:loss = 0.0343967, step = 25101 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.287\n",
      "INFO:tensorflow:loss = 0.0303696, step = 25201 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.212\n",
      "INFO:tensorflow:loss = 0.0291352, step = 25301 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.695\n",
      "INFO:tensorflow:loss = 0.0362407, step = 25401 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.076\n",
      "INFO:tensorflow:loss = 0.0280762, step = 25501 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.22\n",
      "INFO:tensorflow:loss = 0.0340699, step = 25601 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.307\n",
      "INFO:tensorflow:loss = 0.0329946, step = 25701 (0.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.214\n",
      "INFO:tensorflow:loss = 0.0289266, step = 25801 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.118\n",
      "INFO:tensorflow:loss = 0.038018, step = 25901 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.115\n",
      "INFO:tensorflow:loss = 0.0396468, step = 26001 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.881\n",
      "INFO:tensorflow:loss = 0.0333415, step = 26101 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.386\n",
      "INFO:tensorflow:loss = 0.033723, step = 26201 (0.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.042\n",
      "INFO:tensorflow:loss = 0.0314092, step = 26301 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.983\n",
      "INFO:tensorflow:loss = 0.0376107, step = 26401 (0.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.48\n",
      "INFO:tensorflow:loss = 0.0355503, step = 26501 (0.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.086\n",
      "INFO:tensorflow:loss = 0.0303373, step = 26601 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.776\n",
      "INFO:tensorflow:loss = 0.0295005, step = 26701 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.814\n",
      "INFO:tensorflow:loss = 0.0326614, step = 26801 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.037\n",
      "INFO:tensorflow:loss = 0.0306125, step = 26901 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.132\n",
      "INFO:tensorflow:loss = 0.0282099, step = 27001 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.076\n",
      "INFO:tensorflow:loss = 0.0285173, step = 27101 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.756\n",
      "INFO:tensorflow:loss = 0.0331083, step = 27201 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.109\n",
      "INFO:tensorflow:loss = 0.0339975, step = 27301 (0.970 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-18310ec0af27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msummary_hook\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Score accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/virtualenvs/deeplearning/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps)\u001b[0m\n\u001b[1;32m    240\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/virtualenvs/deeplearning/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/virtualenvs/deeplearning/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    516\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/virtualenvs/deeplearning/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/share/virtualenvs/deeplearning/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    947\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/virtualenvs/deeplearning/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1018\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/virtualenvs/deeplearning/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/virtualenvs/deeplearning/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/virtualenvs/deeplearning/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1118\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/virtualenvs/deeplearning/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1315\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1316\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/virtualenvs/deeplearning/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/virtualenvs/deeplearning/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1298\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1299\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Set model params\n",
    "model_params = {\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"dropout\": DROPOUT,\n",
    "    \"optimizer\": OPTIMIZER\n",
    "}\n",
    "\n",
    "# Instantiate Estimator\n",
    "nn = tf.estimator.Estimator(model_fn=model_fn, params=model_params, model_dir=LOGDIR, \n",
    "                            config=tf.estimator.RunConfig(session_config=config))\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': piv.as_matrix()},\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=None,\n",
    "    shuffle=True,\n",
    "    queue_capacity=10000,\n",
    "    num_threads=1,\n",
    ")\n",
    "summary_hook = tf.train.SummarySaverHook(\n",
    "    save_secs=2,\n",
    "    output_dir=LOGDIR,\n",
    "    summary_op=tf.summary.merge_all(),\n",
    "    scaffold=tf.train.Scaffold()\n",
    ")\n",
    "# Train\n",
    "nn.train(input_fn=train_input_fn, steps=30000, hooks=[summary_hook])  #\n",
    "\n",
    "# Score accuracy\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': piv.as_matrix()},  # TODO test data\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "# ev = nn.evaluate(input_fn=test_input_fn)\n",
    "# print(\"Loss: %s\" % ev[\"loss\"])\n",
    "# print(\"Root Mean Squared Error: %s\" % ev[\"rmse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": piv.as_matrix()},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "predictions_gen = nn.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = piv.index.values\n",
    "reverse_index = {}\n",
    "\n",
    "for i, j in enumerate(index):\n",
    "    reverse_index[j] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(index))\n",
    "print(len(reverse_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(predictions_gen)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./mangaki-data-challenge-0908/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(user_id, work_id):\n",
    "    try:\n",
    "        row_num = reverse_index[user_id]\n",
    "    except KeyError: # check if user has no ratings yet and submit global score\n",
    "        return ratings.groupby('work_id').mean()['rating'][work_id]\n",
    "#    print('user_id', row['user_id'], 'index', row_num, 'work', work_id)\n",
    "    return predictions[row_num][work_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['out'] = test.apply(lambda row: get_prediction(int(row['user_id']), row['work_id']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('./deep_ae1_out_adagrad_0.005_64_0.8_64_128_densere.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering On Anime Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on https://www.kaggle.com/ajmichelutti/collaborative-filtering-on-anime-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find works with no rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: As we are subtracting the mean from each rating to standardize\n",
    "# all users with only one rating or who had rated everything the same will be dropped\n",
    "\n",
    "# Normalize the values\n",
    "#piv_norm = piv.apply(lambda x: (x-np.mean(x))/(np.max(x)-np.min(x)), axis=1)\n",
    "piv_norm = piv.apply(lambda x: x / 5, axis=1)\n",
    "\n",
    "\n",
    "# Drop all columns containing only zeros representing users who did not rate\n",
    "piv_norm.fillna(0, inplace=True)\n",
    "piv_norm = piv_norm.T\n",
    "piv_norm = piv_norm.loc[:, (piv_norm != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data needs to be in a sparse matrix format to be read by the following functions\n",
    "\n",
    "piv_sparse = sp.sparse.csr_matrix(piv_norm.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_similarity = cosine_similarity(piv_sparse)\n",
    "user_similarity = cosine_similarity(piv_sparse.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting the similarity matricies into dataframe objects\n",
    "\n",
    "item_sim_df = pd.DataFrame(item_similarity, index = piv_norm.index, columns = piv_norm.index)\n",
    "user_sim_df = pd.DataFrame(user_similarity, index = piv_norm.columns, columns = piv_norm.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing output\n",
    "test = pd.read_csv('./mangaki-data-challenge-0908/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates the weighted average of similar users\n",
    "# to determine a potential rating for an input user and show\n",
    "\n",
    "def predicted_rating(anime_name, user):\n",
    "    sim_users = user_sim_df.sort_values(by=user, ascending=False).index[1:1000]\n",
    "    user_values = user_sim_df.sort_values(by=user, ascending=False).loc[:,user].tolist()[1:1000]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out = [predicted_rating(row['work_id'], row['user_id']) for i, row in test.iterrows()]\n",
    "\n",
    "test['out'] = ratings.apply(lambda row: predicted_rating(row['work_id'], row['user_id']), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Adding MAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
